---
layout: default
title: Kubeflow Part 1
permalink: /kf_01/
---

## So you want to do MLOps?
There's a lot of tools out there to do MlOps, and a lot of talks, blog posts, papers, etc telling you how to use some pretty awesome tools to do pretty awesome things. I've had to wade pretty deep into this stuff lately, and I'll say that much like having a Jira board doesn't mean you're doing Agile, installing Kubeflow (or MLFlow or Seldon or whatever) doesn't mean you're doing MLOps. MLOps is still kind of vaguely defined, but if I were to sum up my understanding right now, it would be that MLOps means having a *plan*. Seems simple enough, but I think it's easy to forget just how much a lot of us are winging it when it comes to data science. 

You sort of hold onto that basic data science framework which is some variation on Clean, Explore, Featurize, Train, Validate, Deploy. This is your first clue that there's a better way of doing things, because we all keep doing the same things over and over again. At least some of them are automatable. More importantly, they are loggable. I think sometimes we get carried away with the automation, but you can never start logging early enough. Making it easier to log what you're doing and having a method of comparing logs from one model to the next, or one project to the next, that's how you get to automation, or how you determine it's time to try something different. But everything in Machine Learning is so *statistical*, and involves so much really chunky, hard-drive-devouring optimization that just recording all the steps is intractable, which is why the whole process is distinct from DevOps. 

And the conditions for change are different, normal software you typically add features and fix bugs. Machine Learning models can run entirely as expected with zero bugs until they start being **wrong all the time**. A model being wrong isn't necessarily a bug, it was obviously right at some point, that why you deployed it. A lot of things lead to model performance degrading over time, the data changes, the labels change, the goals change. Just like we have to occasionally update our understanding of the world, so do machines. It's pretty hard for me, and most humans I've met, so have a little sympathy for the machines, they're even more rigid and literal than people.

## So get to the sick tools!!!!
I've been using Kubeflow, it's not without it's problems, the biggest one that I didn't know any Kubernetes going in. Well, that's my problem, but still, Kubernetes isn't exactly a soft learning curve. Containerization is a good way of ensuring that your code doesn't break just because it switches machines, there are a number of Kubernetes solutions that seem to fall into the category of "this will make it easier to scale up later." There's good reasons to scale things up, but there are plenty of tasks that just aren't going to really scale very quickly. I'll try to point these out as I go, because I've been lead down some very complicated solutions to simple problems and realized that the simple answer was fine. The other major problem Kubeflow has is that Google seems to hate making user friendly open-source projects, and I don't think anyone's made a Keras for Kubeflow yet.  That being said, Kubeflow itself isn't that hard to use, and it's extremely flexible, has a UI, and easily integrates with a lot of other tools, notably MLFlow.

And so for Kubeflow, you need Kubernetes, I'm going to run k3d on my mac, and maybe ina couple more posts see if I can get the windows machine we keep around to play Skyrim to come into the cluster. k3d runs k3s inside a docker container, k3s is of course a lightweight version of k8s, which in turn is a lightweight version of Kubernetes. So in short, k3d is light-light-weight Kubernetes for people who can't even be bothered to install k3s, ie: me.

Installing k3d is just a simple brew install on a mac

docker
go
k3d
kubectl
kustomize
kubeflow manifests
